\clearpage
\chapter{Introduction}
\label{chap:introduction}

As the robotics industry develops, it is becoming increasingly common to see robots used to solve both important, difficult and dangerous tasks. Dealing with real world problems is often the goal when inventors work towards new technologies. Some inventions may be used in a multitude of ways and further the development of other increasingly complex solutions, while others serve society in small but significant ways for decades to come.
As the technologies mature and become more widely available, new possibilities arise. Possibilities to use the technology for less serious tasks and instead focus on showing its capabilities in a fun and eye-catching way. This could be done by using it in an unconventional environment or by completing a task far outside the intend of the inventor.
This project will try to use technology in such a way. It will try to use methods originally developed for the industry to complete an objective it was not intended for.

\section{Project Goals}

Using a UR5 robot arm with an attached gripper, a camera, and software, the aim of this project is to pick up a ball and throw it at a dart board placed within view of the camera. For safety reasons the ball thrown is light weight, made of plastic and is about the size of a ping pong ball. To allow it to stick to the dart board, it is coated with Velcro, just as the dart board is. Success will be measured based on how far the average throw is from the bullseye.

\section{Problem Definition} \label{sec:ProblemDefinition}

\textbf{Make a UR5 robot arm throw an object at a designated target}
\begin{itemize}
	\item Identify the target point using machine vision
	\item Plan a trajectory for the object using physics and kinematics
	\item Control a UR5 and gripper based on modeled trajectory
\end{itemize}
The solution is expected to consistently hit within the visual bullseye of the Velcro dart board, as seen in \textcolor{red}{figure \ref{fig:dartboard}}. Specifically, the center of the ball should be within 2 cm of the center of the bullseye. This accuracy would also allow the solution to hit within the opening of a standard American 16 oz red solo cup with a ping pong ball. The accuracy is accepted to be consistent, if at least 90\% of throws hit within the accepted target area.
Additionally, the solution should require no human intervention once started, apart from placing the ball in a designated pickup area at the start of each throw.
\newline
\newline
\newline
\newline

\section{Constraints \& Limitations}

The developed system is subject to constraints originating from the physical hardware and from assumptions introduced during modelling and implementation. The robot motion is limited by the joint limits and Cartesian workspace boundaries defined by the UR5 safety configuration. Only motions that remain within these limits can be executed. The mechanical design of the gripper constrains the admissible release pose and orientation of the ball.
\newline
\newline
Further limitations arise from modelling and implementation assumptions. The throwing motion is defined as a sequence consisting of lead-up, release, and follow-through phases. The robot–table calibration assumes a rigid and planar table surface and relies on manual TCP positioning during data acquisition. The calibration is treated as static.
\newline
\newline
The vision subsystem assumes a fixed camera pose and stable illumination conditions. The homography-based mapping is valid only for points located on the table plane. Object detection is limited to circular targets within predefined size ranges.
\newline
\newline
Trajectory planning assumes ideal projectile motion at the time of release and does not include aerodynamic effects such as air resistance or spin. Trajectories are computed offline and executed open-loop at a fixed control frequency. Operation of the system requires manual placement of the ball at a predefined pickup location prior to each trial.

\section{System Overview}

The system developed in this project integrates several components that enable the robot to perceive its environment, plan feasible trajectories, and execute accurate motions within a calibrated workspace. The system is structured around five core modules: machine vision, robot–table calibration, trajectory planning, kinematics, and robot control, which operate sequentially and are closely interconnected.

The machine vision module captures images of the table surface and detects the center of the target on the dartboard. This position is initially expressed in the camera coordinate frame and subsequently transformed into world-frame coordinates. The resulting target position is then used as input for the subsequent planning and control stages.

Trajectory planning generates a feasible motion from the robot’s current configuration to the target location while respecting kinematic and workspace constraints. Kinematic computations are used to convert the planned end-effector motion into corresponding joint configurations through inverse kinematics, with forward kinematics used for verification.

The robot control module executes the planned trajectory by commanding the robot joints to follow the desired motion profile. Together, these modules form a modular and integrated system that enables reliable operation within the table workspace. An overview of the complete experimental setup is shown in Figure~\ref{fig:SystemThrow}.


%system billede her 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\textwidth]{images/SystemThrow.png}
	\caption{System overview of the robotic throwing setup.}
	\label{fig:SystemThrow}
\end{figure}

