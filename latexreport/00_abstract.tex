This project presents the design and implementation of an integrated robotic throwing system using a Universal Robots UR5 manipulator. The objective was to enable the robot to detect a target on the table and execute a throwing motion toward the detected target. Achieving this required the integration of calibration, machine vision, trajectory planning, kinematic computation, and robot control within a combined framework.

A machine vision system based on OpenCV was implemented using a fixed camera observing the table workspace. The camera was intrinsically calibrated, and a homography-based mapping was applied to convert detected image coordinates into world frame coordinates. Circular target detection was performed using a Hough transform based method, allowing the center of the target to be estimated and provided as input to the trajectory planning program.

To enable accurate interaction with the workspace, a robot-table calibration was performed to establish the transformation between the world frame and the robot base frame. The calibration was based on manually collected reference points and estimated using an SVD-based least-squares method. Outlier rejection was applied to improve robustness and ensure consistent coordinate mapping.

Throwing trajectories were generated using a simplified projectile motion model combined with computed lead-up, release, and follow-through phases. Kinematic feasibility was ensured through inverse and forward kinematics, and trajectories were executed using the UR5 real-time control interface (UR\_RTDE) at a fixed control frequency.

The implemented system demonstrated autonomous target detection and execution of throwing motions. While reliable and repeatable operation was achieved, the specified accuracy requirement of consistently hitting within 2 cm of the target center was not fully met. The project nevertheless resulted in a complete end-to-end robotic throwing system and provides a basis for further improvement.
